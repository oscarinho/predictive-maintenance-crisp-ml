# ğŸ”§ Predictive Maintenance - CRISP-ML Project

A complete **CRISP-ML** (Cross-Industry Standard Process for Machine Learning) pipeline for predicting machine failures.

## ğŸ“ Project Structure

```
â”œâ”€â”€ CRISP_ML_Predictive_Maintenance.ipynb  # Jupyter Notebook (Phases 1-5)
â”œâ”€â”€ app.py                                  # Streamlit Deployment (Phase 6)
â”œâ”€â”€ predictive_maintenance.csv              # Dataset
â”œâ”€â”€ requirements.txt                        # Dependencies
â”œâ”€â”€ README.md                               # Documentation
â”‚
â””â”€â”€ Model Artifacts (generated by notebook):
    â”œâ”€â”€ model.pkl
    â”œâ”€â”€ scaler.pkl
    â”œâ”€â”€ label_encoder_type.pkl
    â”œâ”€â”€ feature_cols.pkl
    â””â”€â”€ model_metadata.pkl
```

## ğŸ“Š Dataset

Using the [Machine Predictive Maintenance Classification](https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification) dataset from Kaggle.

**Features:**
| Feature | Description |
|---------|-------------|
| Air temperature [K] | Ambient air temperature in Kelvin |
| Process temperature [K] | Machine operating temperature |
| Rotational speed [rpm] | Speed of rotation |
| Torque [Nm] | Applied torque |
| Tool wear [min] | Cumulative tool usage time |
| Type | Product quality (L=Low, M=Medium, H=High) |

**Target:** Binary classification (0 = No Failure, 1 = Failure)

## ğŸ”„ CRISP-ML Pipeline

### Phase 1: Business Understanding
- **Problem:** Predict machine failures before they occur
- **Goal:** Enable proactive maintenance, reduce downtime
- **Success Criteria:** High recall (catch failures), good precision

### Phase 2: Data Understanding
- 10,000 records with 10 features
- Imbalanced dataset (3.39% failure rate)
- 5 failure types + "No Failure"

### Phase 3: Data Preparation
- Dropped ID columns (UDI, Product ID)
- Encoded categorical features (Type)
- **Feature Engineering:**
  - `Temp_diff`: Process temp - Air temp
  - `Power`: Torque Ã— Rotational Speed
  - `Tool_wear_normalized`: Normalized wear
- StandardScaler for feature scaling
- Stratified train-test split (80/20)

### Phase 4: Modeling
Three models compared:
1. Logistic Regression (baseline)
2. Random Forest (balanced)
3. Gradient Boosting

**Best Model:** Tuned Random Forest with hyperparameter optimization

### Phase 5: Evaluation
| Metric | Score |
|--------|-------|
| Accuracy | 99.2% |
| Precision | 93.3% |
| Recall | 82.4% |
| F1 Score | 87.5% |
| ROC-AUC | 96.8% |

### Phase 6: Deployment
Streamlit web application with:
- Real-time predictions
- Interactive data exploration
- Model performance dashboard

## ğŸ“ Project Structure

```
predictive-maintenance/
â”œâ”€â”€ crisp_ml_pipeline.py      # Complete CRISP-ML pipeline
â”œâ”€â”€ app.py                     # Streamlit deployment app
â”œâ”€â”€ predictive_maintenance.csv # Dataset
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # This file
â”‚
â”œâ”€â”€ Model Artifacts/
â”‚   â”œâ”€â”€ model.pkl              # Trained Random Forest model
â”‚   â”œâ”€â”€ scaler.pkl             # StandardScaler
â”‚   â”œâ”€â”€ label_encoder_type.pkl # LabelEncoder for Type
â”‚   â”œâ”€â”€ feature_cols.pkl       # Feature column names
â”‚   â””â”€â”€ model_metadata.pkl     # Model metrics & info
â”‚
â””â”€â”€ Visualizations/
    â”œâ”€â”€ eda_visualizations.png
    â”œâ”€â”€ correlation_heatmap.png
    â””â”€â”€ model_evaluation.png
```

## ğŸš€ Quick Start

### Step 1: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 2: Run Jupyter Notebook (CRISP-ML Phases 1-5)
```bash
jupyter lab CRISP_ML_Predictive_Maintenance.ipynb
```
Execute all cells to:
- Explore and understand the data
- Prepare and engineer features
- Train and evaluate models
- Generate model artifacts (.pkl files)

### Step 3: Deploy with Streamlit (Phase 6)
```bash
streamlit run app.py
```
Open browser at `http://localhost:8501`

## ğŸ³ Docker Deployment (Optional)

```dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8501

CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

Build and run:
```bash
docker build -t predictive-maintenance .
docker run -p 8501:8501 predictive-maintenance
```

## â˜ï¸ Cloud Deployment

### Streamlit Cloud
1. Push code to GitHub
2. Go to [share.streamlit.io](https://share.streamlit.io)
3. Connect your repository
4. Deploy!

### Heroku
Create `Procfile`:
```
web: streamlit run app.py --server.port $PORT --server.address 0.0.0.0
```

## ğŸ“ˆ Model Details

### Feature Importance (Top 5)
1. **Rotational speed [rpm]** - 23.4%
2. **Torque [Nm]** - 19.8%
3. **Power** (engineered) - 18.5%
4. **Tool wear [min]** - 12.1%
5. **Tool_wear_normalized** - 11.1%

### Hyperparameters (Tuned Random Forest)
```python
{
    'n_estimators': 200,
    'max_depth': 20,
    'min_samples_split': 5,
    'min_samples_leaf': 2,
    'class_weight': 'balanced'
}
```

## ğŸ“š CRISP-ML(Q) Framework

This project follows the [CRISP-ML(Q)](https://arxiv.org/abs/2003.05155) methodology:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CRISP-ML(Q) Process                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Business & Data Understanding                           â”‚
â”‚     â””â”€> Define objectives, assess data quality              â”‚
â”‚                                                             â”‚
â”‚  2. Data Engineering (Data Preparation)                     â”‚
â”‚     â””â”€> Clean, transform, feature engineering               â”‚
â”‚                                                             â”‚
â”‚  3. ML Model Engineering (Modeling)                         â”‚
â”‚     â””â”€> Select algorithms, train, tune hyperparameters      â”‚
â”‚                                                             â”‚
â”‚  4. Model Evaluation (Quality Assurance)                    â”‚
â”‚     â””â”€> Validate performance, test robustness               â”‚
â”‚                                                             â”‚
â”‚  5. Model Deployment                                        â”‚
â”‚     â””â”€> Deploy to production, monitor                       â”‚
â”‚                                                             â”‚
â”‚  6. Model Monitoring & Maintenance                          â”‚
â”‚     â””â”€> Track drift, retrain as needed                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Use Cases

1. **Predictive Maintenance**: Schedule maintenance before failures occur
2. **Quality Control**: Identify products at risk of failure
3. **Resource Optimization**: Reduce spare parts inventory
4. **Downtime Reduction**: Minimize unexpected production stoppages

## ğŸ“ License

This project is for educational purposes. Dataset from Kaggle.

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/improvement`)
3. Commit changes (`git commit -am 'Add improvement'`)
4. Push to branch (`git push origin feature/improvement`)
5. Create Pull Request

---

*Built with â¤ï¸ using CRISP-ML methodology and Streamlit*
